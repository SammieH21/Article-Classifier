{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import os\n",
    "import string\n",
    "import re\n",
    "import io\n",
    "import pandas as pd\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from zipfile import ZipFile\n",
    "import requests\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-07-31 17:14:20--  http://mlg.ucd.ie/files/datasets/bbc-fulltext.zip\n",
      "Resolving mlg.ucd.ie (mlg.ucd.ie)... 137.43.93.132\n",
      "Connecting to mlg.ucd.ie (mlg.ucd.ie)|137.43.93.132|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2874078 (2.7M) [application/zip]\n",
      "Saving to: ‘bbc-fulltext.zip’\n",
      "\n",
      "bbc-fulltext.zip    100%[===================>]   2.74M  1.15MB/s    in 2.4s    \n",
      "\n",
      "2021-07-31 17:14:23 (1.15 MB/s) - ‘bbc-fulltext.zip’ saved [2874078/2874078]\n",
      "\n",
      "--2021-07-31 17:14:23--  https://github.com/kmr0877/IMDB-Sentiment-Classification-CBOW-Model/blob/master/glove.6B.50d.txt.gz?raw=true\n",
      "Resolving github.com (github.com)... 140.82.112.4\n",
      "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://github.com/kmr0877/IMDB-Sentiment-Classification-CBOW-Model/raw/master/glove.6B.50d.txt.gz [following]\n",
      "--2021-07-31 17:14:24--  https://github.com/kmr0877/IMDB-Sentiment-Classification-CBOW-Model/raw/master/glove.6B.50d.txt.gz\n",
      "Reusing existing connection to github.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/kmr0877/IMDB-Sentiment-Classification-CBOW-Model/master/glove.6B.50d.txt.gz [following]\n",
      "--2021-07-31 17:14:24--  https://raw.githubusercontent.com/kmr0877/IMDB-Sentiment-Classification-CBOW-Model/master/glove.6B.50d.txt.gz\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 69182520 (66M) [application/octet-stream]\n",
      "Saving to: ‘glove.6B.50d.txt.gz’\n",
      "\n",
      "glove.6B.50d.txt.gz 100%[===================>]  65.98M  12.2MB/s    in 5.5s    \n",
      "\n",
      "2021-07-31 17:14:29 (11.9 MB/s) - ‘glove.6B.50d.txt.gz’ saved [69182520/69182520]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget \"http://mlg.ucd.ie/files/datasets/bbc-fulltext.zip\"\n",
    "!wget \"https://github.com/kmr0877/IMDB-Sentiment-Classification-CBOW-Model/blob/master/glove.6B.50d.txt.gz?raw=true\" -O \"glove.6B.50d.txt.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ZipFile(\"bbc-fulltext.zip\").extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_text_files = os.listdir(\"bbc/business\")\n",
    "entertainment_text_files = os.listdir(\"bbc/entertainment\")\n",
    "politics_text_files = os.listdir(\"bbc/politics\")\n",
    "tech_text_files = os.listdir(\"bbc/tech\")\n",
    "sports_text_files = os.listdir(\"bbc/sport\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_text(file,directory):\n",
    "    file_path = directory + \"/\" + file\n",
    "    #print(file_path)\n",
    "    try:\n",
    "        with open(file_path,'r') as f:\n",
    "            text = f.read()\n",
    "\n",
    "    # at least one file is ISO-8859-14 encoded. That could cause some issues unless accounted for\n",
    "    except UnicodeDecodeError:\n",
    "        with open(file_path,'r',encoding=\"ISO-8859-14\") as f:\n",
    "            text = f.read()\n",
    "    return text\n",
    "\n",
    "business_texts = [read_text(text_file,directory=\"bbc/business\") for text_file in business_text_files]\n",
    "entertainment_texts = [read_text(text_file,directory=\"bbc/entertainment\") for text_file in entertainment_text_files]\n",
    "politics_texts = [read_text(text_file,directory=\"bbc/politics\") for text_file in politics_text_files]\n",
    "tech_texts = [read_text(text_file,directory=\"bbc/tech\") for text_file in tech_text_files]\n",
    "sport_texts = [read_text(text_file,directory=\"bbc/sport\") for text_file in sports_text_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_texts = [business_texts, entertainment_texts, politics_texts, tech_texts, sport_texts]\n",
    "text_idx = [0,1,2,3,4]\n",
    "article_types = [\"business\",\"entertainment\",\"politics\",\"tech\",\"sports\"]\n",
    "class_dict = dict(zip(text_idx,article_types))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = [ \"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \"at\",\n",
    "             \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"could\", \"did\", \"do\",\n",
    "             \"does\", \"doing\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"has\", \"have\",\n",
    "             \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \"here's\", \"hers\", \"herself\", \"him\", \"himself\",\n",
    "             \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\", \"is\", \"it\", \"it's\", \"its\",\n",
    "             \"itself\", \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\", \"once\", \"only\", \"or\", \"other\",\n",
    "             \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"she\", \"she'd\", \"she'll\", \"she's\",\n",
    "              \"should\", \"so\", \"some\", \"such\", \"than\", \"that\", \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\",\n",
    "             \"then\", \"there\", \"there's\", \"these\", \"they\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"this\", \"those\",\n",
    "             \"through\", \"to\", \"too\", \"under\", \"until\", \"up\", \"very\", \"was\", \"we\", \"we'd\", \"we'll\", \"we're\", \"we've\",\n",
    "             \"were\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\", \"which\", \"while\", \"who\", \"who's\", \"whom\",\n",
    "             \"why\", \"why's\", \"with\", \"would\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\", \"your\", \"yours\",\n",
    "             \"yourself\", \"yourselves\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[text,label] for (texts, label) in zip(all_texts,text_idx) for text in texts],columns=[\"text\",\"label\"])\n",
    "df_train, df_test = train_test_split(df, train_size=.8,random_state=111)\n",
    "df_train = df_train.copy()\n",
    "df_test = df_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text):\n",
    "    processed_text = \" \".join([word for word in re.sub(\"\\.+\", \". \", re.sub(\"[\\(\\)\\[\\]\\\"\\']\",\"\",text.replace(\"\\n|\\w+\", \" \"))).split(\" \") if word.lower().strip() not in stopwords])\n",
    "    return processed_text\n",
    "\n",
    "def remove_punctuation(text):\n",
    "     return text.translate(str.maketrans('', '', string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sentences = [sentence.strip() for text in df_train.text.values for sentence in text.split(\".\") if sentence.strip() != \"\"]\n",
    "\n",
    "tokenizer = Tokenizer(oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(all_sentences)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "reverse_idx = {value :key for (key, value) in word_index.items()}\n",
    "\n",
    "maxlen = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['tokenized'] = df_train.text.apply(lambda text: tokenizer.texts_to_sequences([text])[0])\n",
    "df_train[\"tokenized\"] = [sequence for sequence in pad_sequences(df_train.tokenized.values,maxlen=maxlen,truncating=\"post\",padding=\"post\")]\n",
    "\n",
    "df_test['tokenized'] = df_test.text.apply(lambda text: tokenizer.texts_to_sequences([text])[0])\n",
    "df_test[\"tokenized\"] = [sequence for sequence in pad_sequences(df_test.tokenized.values,maxlen=maxlen,truncating=\"post\",padding=\"post\")]\n",
    "train_X = np.vstack(df_train[\"tokenized\"].values)\n",
    "test_X = np.vstack(df_test[\"tokenized\"].values)\n",
    "\n",
    "train_y = to_categorical(df_train.label.values)\n",
    "test_y = to_categorical(df_test.label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open(\"glove.6B.50d.txt.gz\", 'r') as f:\n",
    "    embedding_list = f.read().decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_vectors = {}\n",
    "for embedding_line in embedding_list.split(\"\\n\"):\n",
    "    embedding_split = embedding_line.split(\" \")\n",
    "    embedding_vectors[embedding_split[0]] = embedding_split[1:]\n",
    "\n",
    "vocab_size = len(word_index.keys()) + 1\n",
    "\n",
    "embedding_matrix = np.zeros((vocab_size,50))\n",
    "\n",
    "for word,i  in word_index.items():\n",
    "    vector = embedding_vectors.get(word)\n",
    "    if vector is not None:\n",
    "        embedding_matrix[i,:] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(word_index.keys()) + 1\n",
    "\n",
    "embedding_matrix = np.zeros((vocab_size,50))\n",
    "\n",
    "for word,i  in word_index.items():\n",
    "    vector = embedding_vectors.get(word)\n",
    "    if vector is not None:\n",
    "        embedding_matrix[i,:] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 500, 50)           1481250   \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 491, 64)           32064     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 122, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 118, 128)          41088     \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 20)                2580      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 105       \n",
      "=================================================================\n",
      "Total params: 1,557,087\n",
      "Trainable params: 75,837\n",
      "Non-trainable params: 1,481,250\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## Model 1 ##\n",
    "\n",
    "model1 = keras.models.Sequential([keras.layers.Embedding(vocab_size, 50, input_length = maxlen, weights= [embedding_matrix],\n",
    "                                                        trainable=False, mask_zero=True),\n",
    "                                 keras.layers.Conv1D(64, 10,activation='relu'),\n",
    "                                 keras.layers.MaxPooling1D(4),\n",
    "                                 keras.layers.Conv1D(128, 5,activation='relu'),\n",
    "                                 keras.layers.GlobalAveragePooling1D(),\n",
    "                                 keras.layers.Dense(20,activation=\"relu\"),\n",
    "                                 keras.layers.Dropout(.2),\n",
    "                                 keras.layers.Dense(5, activation=\"softmax\")\n",
    "                                ])\n",
    "\n",
    "model1.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\",metrics=['accuracy'])\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "55/55 [==============================] - 5s 66ms/step - loss: 1.3615 - accuracy: 0.3699 - val_loss: 0.5795 - val_accuracy: 0.7524\n",
      "Epoch 2/50\n",
      "55/55 [==============================] - 2s 45ms/step - loss: 0.6222 - accuracy: 0.7335 - val_loss: 0.4249 - val_accuracy: 0.8534\n",
      "Epoch 3/50\n",
      "55/55 [==============================] - 2s 45ms/step - loss: 0.4101 - accuracy: 0.8460 - val_loss: 0.2424 - val_accuracy: 0.9255\n",
      "Epoch 4/50\n",
      "55/55 [==============================] - 2s 40ms/step - loss: 0.3235 - accuracy: 0.8848 - val_loss: 0.2184 - val_accuracy: 0.9351\n",
      "Epoch 5/50\n",
      "55/55 [==============================] - 2s 40ms/step - loss: 0.2499 - accuracy: 0.9260 - val_loss: 0.1665 - val_accuracy: 0.9471\n",
      "Epoch 6/50\n",
      "55/55 [==============================] - 2s 39ms/step - loss: 0.1924 - accuracy: 0.9394 - val_loss: 0.1557 - val_accuracy: 0.9495\n",
      "Epoch 7/50\n",
      "55/55 [==============================] - 2s 40ms/step - loss: 0.1738 - accuracy: 0.9426 - val_loss: 0.1277 - val_accuracy: 0.9567\n",
      "Epoch 8/50\n",
      "55/55 [==============================] - 2s 41ms/step - loss: 0.1423 - accuracy: 0.9568 - val_loss: 0.1460 - val_accuracy: 0.9495\n",
      "Epoch 9/50\n",
      "55/55 [==============================] - 2s 40ms/step - loss: 0.1475 - accuracy: 0.9504 - val_loss: 0.1424 - val_accuracy: 0.9519\n",
      "Epoch 10/50\n",
      "55/55 [==============================] - 2s 39ms/step - loss: 0.1452 - accuracy: 0.9530 - val_loss: 0.1216 - val_accuracy: 0.9567\n",
      "Epoch 11/50\n",
      "55/55 [==============================] - 2s 40ms/step - loss: 0.1234 - accuracy: 0.9598 - val_loss: 0.1067 - val_accuracy: 0.9567\n",
      "Epoch 12/50\n",
      "55/55 [==============================] - 3s 46ms/step - loss: 0.1007 - accuracy: 0.9718 - val_loss: 0.0885 - val_accuracy: 0.9688\n",
      "Epoch 13/50\n",
      "55/55 [==============================] - 2s 42ms/step - loss: 0.0771 - accuracy: 0.9767 - val_loss: 0.0970 - val_accuracy: 0.9639\n",
      "Epoch 14/50\n",
      "55/55 [==============================] - 2s 41ms/step - loss: 0.0985 - accuracy: 0.9656 - val_loss: 0.1284 - val_accuracy: 0.9591\n",
      "Epoch 15/50\n",
      "55/55 [==============================] - 2s 40ms/step - loss: 0.0869 - accuracy: 0.9691 - val_loss: 0.0896 - val_accuracy: 0.9615\n",
      "Epoch 16/50\n",
      "55/55 [==============================] - 2s 40ms/step - loss: 0.0554 - accuracy: 0.9850 - val_loss: 0.0895 - val_accuracy: 0.9591\n",
      "Epoch 17/50\n",
      "55/55 [==============================] - 2s 40ms/step - loss: 0.0805 - accuracy: 0.9760 - val_loss: 0.1018 - val_accuracy: 0.9591\n",
      "Epoch 18/50\n",
      "55/55 [==============================] - 2s 41ms/step - loss: 0.0637 - accuracy: 0.9807 - val_loss: 0.0890 - val_accuracy: 0.9688\n",
      "Epoch 19/50\n",
      "55/55 [==============================] - 2s 40ms/step - loss: 0.0885 - accuracy: 0.9731 - val_loss: 0.1455 - val_accuracy: 0.9543\n",
      "Epoch 20/50\n",
      "55/55 [==============================] - 2s 41ms/step - loss: 0.0337 - accuracy: 0.9956 - val_loss: 0.1190 - val_accuracy: 0.9736\n",
      "Epoch 21/50\n",
      "55/55 [==============================] - 2s 39ms/step - loss: 0.0560 - accuracy: 0.9828 - val_loss: 0.0682 - val_accuracy: 0.9736\n",
      "Epoch 22/50\n",
      "55/55 [==============================] - 2s 40ms/step - loss: 0.0496 - accuracy: 0.9855 - val_loss: 0.2082 - val_accuracy: 0.9615\n",
      "Epoch 23/50\n",
      "55/55 [==============================] - 2s 40ms/step - loss: 0.0651 - accuracy: 0.9788 - val_loss: 0.0830 - val_accuracy: 0.9736\n",
      "Epoch 24/50\n",
      "55/55 [==============================] - 2s 40ms/step - loss: 0.0450 - accuracy: 0.9848 - val_loss: 0.1124 - val_accuracy: 0.9639\n",
      "Epoch 25/50\n",
      "55/55 [==============================] - 2s 45ms/step - loss: 0.0369 - accuracy: 0.9941 - val_loss: 0.0985 - val_accuracy: 0.9663\n",
      "Epoch 26/50\n",
      "55/55 [==============================] - 2s 42ms/step - loss: 0.0324 - accuracy: 0.9883 - val_loss: 0.1129 - val_accuracy: 0.9615\n",
      "Epoch 27/50\n",
      "55/55 [==============================] - 2s 44ms/step - loss: 0.0201 - accuracy: 0.9927 - val_loss: 0.1475 - val_accuracy: 0.9639\n",
      "Epoch 28/50\n",
      "55/55 [==============================] - 2s 42ms/step - loss: 0.0487 - accuracy: 0.9877 - val_loss: 0.2496 - val_accuracy: 0.9519\n",
      "Epoch 29/50\n",
      "55/55 [==============================] - 2s 41ms/step - loss: 0.0577 - accuracy: 0.9873 - val_loss: 0.1015 - val_accuracy: 0.9688\n",
      "Epoch 30/50\n",
      "55/55 [==============================] - 2s 40ms/step - loss: 0.0224 - accuracy: 0.9959 - val_loss: 0.1749 - val_accuracy: 0.9663\n",
      "Epoch 31/50\n",
      "55/55 [==============================] - 2s 40ms/step - loss: 0.0369 - accuracy: 0.9895 - val_loss: 0.1223 - val_accuracy: 0.9736\n",
      "Epoch 32/50\n",
      "55/55 [==============================] - 2s 40ms/step - loss: 0.0347 - accuracy: 0.9907 - val_loss: 0.0830 - val_accuracy: 0.9760\n",
      "Epoch 33/50\n",
      "55/55 [==============================] - 2s 40ms/step - loss: 0.0132 - accuracy: 0.9991 - val_loss: 0.0910 - val_accuracy: 0.9688\n",
      "Epoch 34/50\n",
      "55/55 [==============================] - 2s 40ms/step - loss: 0.0211 - accuracy: 0.9934 - val_loss: 0.1344 - val_accuracy: 0.9615\n",
      "Epoch 35/50\n",
      "55/55 [==============================] - 2s 40ms/step - loss: 0.0109 - accuracy: 0.9982 - val_loss: 0.1155 - val_accuracy: 0.9736\n",
      "Epoch 36/50\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 0.0130 - accuracy: 0.9962 - val_loss: 0.1195 - val_accuracy: 0.9688\n",
      "Epoch 37/50\n",
      "55/55 [==============================] - 2s 40ms/step - loss: 0.0101 - accuracy: 0.9961 - val_loss: 0.1329 - val_accuracy: 0.9663\n",
      "Epoch 38/50\n",
      "55/55 [==============================] - 2s 40ms/step - loss: 0.0138 - accuracy: 0.9948 - val_loss: 0.1389 - val_accuracy: 0.9688\n",
      "Epoch 39/50\n",
      "55/55 [==============================] - 2s 44ms/step - loss: 0.0296 - accuracy: 0.9901 - val_loss: 0.1405 - val_accuracy: 0.9663\n",
      "Epoch 40/50\n",
      "55/55 [==============================] - 2s 42ms/step - loss: 0.0190 - accuracy: 0.9906 - val_loss: 0.0991 - val_accuracy: 0.9663\n",
      "Epoch 41/50\n",
      "55/55 [==============================] - 2s 43ms/step - loss: 0.0091 - accuracy: 0.9973 - val_loss: 0.1003 - val_accuracy: 0.9639\n",
      "Epoch 42/50\n",
      "55/55 [==============================] - 2s 42ms/step - loss: 0.0312 - accuracy: 0.9890 - val_loss: 0.1354 - val_accuracy: 0.9688\n",
      "Epoch 43/50\n",
      "55/55 [==============================] - 2s 40ms/step - loss: 0.0359 - accuracy: 0.9882 - val_loss: 0.0857 - val_accuracy: 0.9736\n",
      "Epoch 44/50\n",
      "55/55 [==============================] - 2s 40ms/step - loss: 0.0158 - accuracy: 0.9953 - val_loss: 0.0673 - val_accuracy: 0.9784\n",
      "Epoch 45/50\n",
      "55/55 [==============================] - 2s 40ms/step - loss: 0.0176 - accuracy: 0.9932 - val_loss: 0.0973 - val_accuracy: 0.9688\n",
      "Epoch 46/50\n",
      "55/55 [==============================] - 2s 45ms/step - loss: 0.0194 - accuracy: 0.9921 - val_loss: 0.1038 - val_accuracy: 0.9736\n",
      "Epoch 47/50\n",
      "55/55 [==============================] - 2s 45ms/step - loss: 0.0088 - accuracy: 0.9984 - val_loss: 0.0905 - val_accuracy: 0.9736\n",
      "Epoch 48/50\n",
      "55/55 [==============================] - 2s 41ms/step - loss: 0.0066 - accuracy: 0.9993 - val_loss: 0.1299 - val_accuracy: 0.9688\n",
      "Epoch 49/50\n",
      "55/55 [==============================] - 2s 42ms/step - loss: 0.0070 - accuracy: 0.9975 - val_loss: 0.1022 - val_accuracy: 0.9736\n",
      "Epoch 50/50\n",
      "55/55 [==============================] - 2s 41ms/step - loss: 0.0093 - accuracy: 0.9978 - val_loss: 0.0853 - val_accuracy: 0.9808\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd356b32490>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(train_X, train_y,validation_data=(test_X,test_y),\n",
    "            epochs=50, batch_size=32, steps_per_epoch= 55,validation_steps=32,validation_batch_size=13,\n",
    "          workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 500, 50)           1481250   \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_1 ( (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20)                1020      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 105       \n",
      "=================================================================\n",
      "Total params: 1,482,375\n",
      "Trainable params: 1,482,375\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## Model 2 ##\n",
    "model2 = keras.models.Sequential([keras.layers.Embedding(vocab_size, 50, input_length = maxlen,\n",
    "                                                        mask_zero=True),\n",
    "                                 keras.layers.GlobalAveragePooling1D(),\n",
    "                                 keras.layers.Dropout(.2),\n",
    "                                 keras.layers.Dense(20,activation=\"relu\"),\n",
    "                                 keras.layers.Dropout(.2),\n",
    "                                 keras.layers.Dense(5, activation=\"softmax\")\n",
    "                                ])\n",
    "\n",
    "model2.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\",metrics=['accuracy'])\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "55/55 [==============================] - 3s 23ms/step - loss: 1.6009 - accuracy: 0.3140 - val_loss: 1.5547 - val_accuracy: 0.8125\n",
      "Epoch 2/50\n",
      "55/55 [==============================] - 1s 18ms/step - loss: 1.5112 - accuracy: 0.7806 - val_loss: 1.3768 - val_accuracy: 0.8005\n",
      "Epoch 3/50\n",
      "55/55 [==============================] - 1s 18ms/step - loss: 1.2883 - accuracy: 0.7590 - val_loss: 1.0844 - val_accuracy: 0.8341\n",
      "Epoch 4/50\n",
      "55/55 [==============================] - 1s 19ms/step - loss: 0.9642 - accuracy: 0.8115 - val_loss: 0.7917 - val_accuracy: 0.9279\n",
      "Epoch 5/50\n",
      "55/55 [==============================] - 1s 18ms/step - loss: 0.6750 - accuracy: 0.8924 - val_loss: 0.5567 - val_accuracy: 0.9423\n",
      "Epoch 6/50\n",
      "55/55 [==============================] - 1s 22ms/step - loss: 0.4499 - accuracy: 0.9506 - val_loss: 0.4000 - val_accuracy: 0.9495\n",
      "Epoch 7/50\n",
      "55/55 [==============================] - 1s 20ms/step - loss: 0.3306 - accuracy: 0.9618 - val_loss: 0.2983 - val_accuracy: 0.9543\n",
      "Epoch 8/50\n",
      "55/55 [==============================] - 1s 20ms/step - loss: 0.2343 - accuracy: 0.9744 - val_loss: 0.2349 - val_accuracy: 0.9639\n",
      "Epoch 9/50\n",
      "55/55 [==============================] - 1s 18ms/step - loss: 0.1820 - accuracy: 0.9811 - val_loss: 0.1931 - val_accuracy: 0.9639\n",
      "Epoch 10/50\n",
      "55/55 [==============================] - 1s 18ms/step - loss: 0.1501 - accuracy: 0.9848 - val_loss: 0.1646 - val_accuracy: 0.9663\n",
      "Epoch 11/50\n",
      "55/55 [==============================] - 1s 19ms/step - loss: 0.1245 - accuracy: 0.9803 - val_loss: 0.1453 - val_accuracy: 0.9639\n",
      "Epoch 12/50\n",
      "55/55 [==============================] - 1s 17ms/step - loss: 0.0908 - accuracy: 0.9924 - val_loss: 0.1316 - val_accuracy: 0.9663\n",
      "Epoch 13/50\n",
      "55/55 [==============================] - 1s 18ms/step - loss: 0.0757 - accuracy: 0.9932 - val_loss: 0.1187 - val_accuracy: 0.9688\n",
      "Epoch 14/50\n",
      "55/55 [==============================] - 1s 18ms/step - loss: 0.0702 - accuracy: 0.9926 - val_loss: 0.1119 - val_accuracy: 0.9736\n",
      "Epoch 15/50\n",
      "55/55 [==============================] - 1s 18ms/step - loss: 0.0632 - accuracy: 0.9913 - val_loss: 0.1047 - val_accuracy: 0.9760\n",
      "Epoch 16/50\n",
      "55/55 [==============================] - 1s 19ms/step - loss: 0.0490 - accuracy: 0.9972 - val_loss: 0.0982 - val_accuracy: 0.9712\n",
      "Epoch 17/50\n",
      "55/55 [==============================] - 1s 17ms/step - loss: 0.0432 - accuracy: 0.9962 - val_loss: 0.0959 - val_accuracy: 0.9760\n",
      "Epoch 18/50\n",
      "55/55 [==============================] - 1s 18ms/step - loss: 0.0452 - accuracy: 0.9930 - val_loss: 0.0900 - val_accuracy: 0.9688\n",
      "Epoch 19/50\n",
      "55/55 [==============================] - 1s 17ms/step - loss: 0.0332 - accuracy: 0.9983 - val_loss: 0.0883 - val_accuracy: 0.9712\n",
      "Epoch 20/50\n",
      "55/55 [==============================] - 1s 17ms/step - loss: 0.0331 - accuracy: 0.9964 - val_loss: 0.0855 - val_accuracy: 0.9712\n",
      "Epoch 21/50\n",
      "55/55 [==============================] - 1s 17ms/step - loss: 0.0261 - accuracy: 0.9984 - val_loss: 0.0810 - val_accuracy: 0.9736\n",
      "Epoch 22/50\n",
      "55/55 [==============================] - 1s 17ms/step - loss: 0.0279 - accuracy: 0.9985 - val_loss: 0.0796 - val_accuracy: 0.9712\n",
      "Epoch 23/50\n",
      "55/55 [==============================] - 1s 17ms/step - loss: 0.0271 - accuracy: 0.9982 - val_loss: 0.0777 - val_accuracy: 0.9736\n",
      "Epoch 24/50\n",
      "55/55 [==============================] - 1s 17ms/step - loss: 0.0181 - accuracy: 0.9991 - val_loss: 0.0761 - val_accuracy: 0.9760\n",
      "Epoch 25/50\n",
      "55/55 [==============================] - 1s 17ms/step - loss: 0.0206 - accuracy: 1.0000 - val_loss: 0.0769 - val_accuracy: 0.9688\n",
      "Epoch 26/50\n",
      "55/55 [==============================] - 1s 18ms/step - loss: 0.0238 - accuracy: 0.9961 - val_loss: 0.0764 - val_accuracy: 0.9712\n",
      "Epoch 27/50\n",
      "55/55 [==============================] - 1s 17ms/step - loss: 0.0164 - accuracy: 0.9985 - val_loss: 0.0739 - val_accuracy: 0.9760\n",
      "Epoch 28/50\n",
      "55/55 [==============================] - 1s 18ms/step - loss: 0.0181 - accuracy: 0.9981 - val_loss: 0.0742 - val_accuracy: 0.9784\n",
      "Epoch 29/50\n",
      "55/55 [==============================] - 1s 17ms/step - loss: 0.0120 - accuracy: 0.9990 - val_loss: 0.0736 - val_accuracy: 0.9784\n",
      "Epoch 30/50\n",
      "55/55 [==============================] - 1s 22ms/step - loss: 0.0137 - accuracy: 0.9992 - val_loss: 0.0753 - val_accuracy: 0.9736\n",
      "Epoch 31/50\n",
      "55/55 [==============================] - 1s 19ms/step - loss: 0.0115 - accuracy: 0.9991 - val_loss: 0.0716 - val_accuracy: 0.9736\n",
      "Epoch 32/50\n",
      "55/55 [==============================] - 1s 20ms/step - loss: 0.0165 - accuracy: 0.9976 - val_loss: 0.0719 - val_accuracy: 0.9736\n",
      "Epoch 33/50\n",
      "55/55 [==============================] - 1s 19ms/step - loss: 0.0124 - accuracy: 0.9982 - val_loss: 0.0710 - val_accuracy: 0.9784\n",
      "Epoch 34/50\n",
      "55/55 [==============================] - 1s 19ms/step - loss: 0.0115 - accuracy: 0.9981 - val_loss: 0.0696 - val_accuracy: 0.9784\n",
      "Epoch 35/50\n",
      "55/55 [==============================] - 1s 19ms/step - loss: 0.0111 - accuracy: 0.9983 - val_loss: 0.0703 - val_accuracy: 0.9784\n",
      "Epoch 36/50\n",
      "55/55 [==============================] - 1s 19ms/step - loss: 0.0116 - accuracy: 0.9982 - val_loss: 0.0707 - val_accuracy: 0.9784\n",
      "Epoch 37/50\n",
      "55/55 [==============================] - 1s 19ms/step - loss: 0.0108 - accuracy: 0.9980 - val_loss: 0.0707 - val_accuracy: 0.9760\n",
      "Epoch 38/50\n",
      "55/55 [==============================] - 1s 18ms/step - loss: 0.0093 - accuracy: 0.9995 - val_loss: 0.0723 - val_accuracy: 0.9736\n",
      "Epoch 39/50\n",
      "55/55 [==============================] - 1s 17ms/step - loss: 0.0089 - accuracy: 0.9968 - val_loss: 0.0674 - val_accuracy: 0.9784\n",
      "Epoch 40/50\n",
      "55/55 [==============================] - 1s 17ms/step - loss: 0.0119 - accuracy: 0.9960 - val_loss: 0.0670 - val_accuracy: 0.9760\n",
      "Epoch 41/50\n",
      "55/55 [==============================] - 1s 18ms/step - loss: 0.0097 - accuracy: 0.9989 - val_loss: 0.0690 - val_accuracy: 0.9736\n",
      "Epoch 42/50\n",
      "55/55 [==============================] - 1s 17ms/step - loss: 0.0075 - accuracy: 0.9990 - val_loss: 0.0718 - val_accuracy: 0.9760\n",
      "Epoch 43/50\n",
      "55/55 [==============================] - 1s 17ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.0704 - val_accuracy: 0.9760\n",
      "Epoch 44/50\n",
      "55/55 [==============================] - 1s 17ms/step - loss: 0.0071 - accuracy: 0.9991 - val_loss: 0.0687 - val_accuracy: 0.9760\n",
      "Epoch 45/50\n",
      "55/55 [==============================] - 1s 17ms/step - loss: 0.0076 - accuracy: 0.9995 - val_loss: 0.0700 - val_accuracy: 0.9736\n",
      "Epoch 46/50\n",
      "55/55 [==============================] - 1s 18ms/step - loss: 0.0066 - accuracy: 0.9998 - val_loss: 0.0693 - val_accuracy: 0.9760\n",
      "Epoch 47/50\n",
      "55/55 [==============================] - 1s 17ms/step - loss: 0.0075 - accuracy: 0.9993 - val_loss: 0.0739 - val_accuracy: 0.9712\n",
      "Epoch 48/50\n",
      "55/55 [==============================] - 1s 17ms/step - loss: 0.0057 - accuracy: 0.9991 - val_loss: 0.0702 - val_accuracy: 0.9736\n",
      "Epoch 49/50\n",
      "55/55 [==============================] - 1s 18ms/step - loss: 0.0074 - accuracy: 0.9991 - val_loss: 0.0676 - val_accuracy: 0.9736\n",
      "Epoch 50/50\n",
      "55/55 [==============================] - 1s 17ms/step - loss: 0.0089 - accuracy: 0.9974 - val_loss: 0.0686 - val_accuracy: 0.9712\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd308220220>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(train_X, train_y,validation_data=(test_X,test_y),\n",
    "            epochs=50, batch_size=32, steps_per_epoch= 55,validation_steps=32,validation_batch_size=13,\n",
    "          workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = model2.layers[0].get_weights()[0]\n",
    "\n",
    "word_vectors = {reverse_idx[i]:model2.layers[0].weights[0][i].numpy() for i in range(1, vocab_size)}\n",
    "\n",
    "out_v = io.open('vecs.tsv', 'w', encoding='utf-8')\n",
    "out_m = io.open('meta.tsv', 'w', encoding='utf-8')\n",
    "\n",
    "for word, vector in word_vectors.items():\n",
    "    if not np.all(vector == 0):\n",
    "        out_m.write(word + \"\\n\")\n",
    "        out_v.write('\\t'.join([str(x) for x in vector]) + \"\\n\")\n",
    "out_v.close()\n",
    "out_m.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text, model=model2,verbose=True):\n",
    "    if verbose:\n",
    "        print(\"#####################################\\nAnalyzing Statement:\\n\"+text)\n",
    "    processed_text = process_text(remove_punctuation(text))\n",
    "    tokenized_text = tokenizer.texts_to_sequences([processed_text])[0]\n",
    "    padded_sequence = pad_sequences([tokenized_text],maxlen=maxlen,truncating=\"post\",padding=\"post\")\n",
    "    likelihoods = model.predict(padded_sequence)[0]\n",
    "    idx = np.argmax(likelihoods)\n",
    "    highest_probability = likelihoods[idx]\n",
    "    class_prediction = class_dict[idx]\n",
    "    if verbose:\n",
    "        print(\"\\nClass:\",class_prediction,\"\\nLikelihood:\",str(highest_probability*100)+\"%\")\n",
    "        print(\"#####################################\\n\\n\")\n",
    "    return class_prediction, highest_probability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####################################\n",
      "Analyzing Statement:\n",
      "Liverpool wins the match!\n",
      "\n",
      "Class: sports \n",
      "Likelihood: 100.0%\n",
      "#####################################\n",
      "\n",
      "\n",
      "#####################################\n",
      "Analyzing Statement:\n",
      "TV\n",
      "\n",
      "Class: entertainment \n",
      "Likelihood: 100.0%\n",
      "#####################################\n",
      "\n",
      "\n",
      "#####################################\n",
      "Analyzing Statement:\n",
      "Democracy\n",
      "\n",
      "Class: politics \n",
      "Likelihood: 99.99970197677612%\n",
      "#####################################\n",
      "\n",
      "\n",
      "#####################################\n",
      "Analyzing Statement:\n",
      "nvidia\n",
      "\n",
      "Class: politics \n",
      "Likelihood: 70.87598443031311%\n",
      "#####################################\n",
      "\n",
      "\n",
      "#####################################\n",
      "Analyzing Statement:\n",
      "video driver\n",
      "\n",
      "Class: tech \n",
      "Likelihood: 99.99996423721313%\n",
      "#####################################\n",
      "\n",
      "\n",
      "#####################################\n",
      "Analyzing Statement:\n",
      "luxury\n",
      "\n",
      "Class: business \n",
      "Likelihood: 100.0%\n",
      "#####################################\n",
      "\n",
      "\n",
      "#####################################\n",
      "Analyzing Statement:\n",
      "stocks\n",
      "\n",
      "Class: business \n",
      "Likelihood: 100.0%\n",
      "#####################################\n",
      "\n",
      "\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "predict(\"Liverpool wins the match!\")\n",
    "predict(\"TV\")\n",
    "predict(\"Democracy\")\n",
    "predict(\"nvidia\")\n",
    "predict(\"video driver\")\n",
    "predict(\"luxury\")\n",
    "predict(\"stocks\")\n",
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
